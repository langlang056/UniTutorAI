"""Gemini LLM æœåŠ¡"""
import google.generativeai as genai
from app.config import get_settings
from PIL import Image
from typing import List, Optional

settings = get_settings()

# å®‰å…¨è®¾ç½®ï¼šç¦ç”¨æ‰€æœ‰è¿‡æ»¤å™¨ï¼ˆå­¦æœ¯å†…å®¹ï¼‰
SAFETY_SETTINGS = [
    {"category": cat, "threshold": "BLOCK_NONE"}
    for cat in [
        "HARM_CATEGORY_HARASSMENT",
        "HARM_CATEGORY_HATE_SPEECH",
        "HARM_CATEGORY_SEXUALLY_EXPLICIT",
        "HARM_CATEGORY_DANGEROUS_CONTENT",
    ]
]

# æ”¹è¿›çš„æç¤ºè¯æ¨¡æ¿ï¼ˆå‚è€ƒè€é¡¹ç›®ï¼‰
DEFAULT_PROMPT_TEMPLATE = """è¯·ä½œä¸ºä¸€åä¸“ä¸šçš„æ•™å¸ˆ,è¯¦ç»†åˆ†æè¿™ä¸€é¡µè¯¾ä»¶çš„å†…å®¹ã€‚

è¯·åŒ…æ‹¬ä»¥ä¸‹å†…å®¹:
1. **ä¸»é¢˜æ¦‚è¿°**: è¿™ä¸€é¡µçš„ä¸»è¦ä¸»é¢˜æ˜¯ä»€ä¹ˆ?
2. **æ ¸å¿ƒæ¦‚å¿µ**: åˆ—å‡ºå¹¶è§£é‡Šé¡µé¢ä¸Šçš„å…³é”®æ¦‚å¿µã€å®šä¹‰æˆ–æœ¯è¯­
3. **å…¬å¼å’Œå›¾è¡¨**: å¦‚æœæœ‰æ•°å­¦å…¬å¼ã€å›¾è¡¨æˆ–å›¾ç¤º,è¯·è¯¦ç»†è§£é‡Šå®ƒä»¬çš„å«ä¹‰
4. **é‡ç‚¹éš¾ç‚¹**: æŒ‡å‡ºè¿™ä¸€é¡µä¸­å­¦ç”Ÿå¯èƒ½éš¾ä»¥ç†è§£çš„éƒ¨åˆ†
5. **çŸ¥è¯†ç‚¹æ€»ç»“**: ç”¨ç®€æ´çš„è¯­è¨€æ€»ç»“è¿™ä¸€é¡µçš„è¦ç‚¹
6. **ä¸å‰æ–‡è”ç³»**: å¦‚æœæä¾›äº†å‰é¢é¡µé¢çš„ä¿¡æ¯,è¯·è¯´æ˜è¿™ä¸€é¡µå¦‚ä½•æ‰¿æ¥æˆ–æ·±åŒ–å‰é¢çš„å†…å®¹

è¯·ç”¨æ¸…æ™°ã€æ˜“æ‡‚çš„ä¸­æ–‡å›ç­”,å°±åƒåœ¨ç»™å­¦ç”Ÿè®²è§£ä¸€æ ·ã€‚ä½¿ç”¨Markdownæ ¼å¼è¾“å‡ºã€‚"""


class GeminiService:
    """Gemini Vision æœåŠ¡"""

    def __init__(self):
        if not settings.google_api_key:
            raise ValueError("GOOGLE_API_KEY æœªé…ç½®")

        genai.configure(api_key=settings.google_api_key)
        self.model = genai.GenerativeModel(settings.google_model)
        self.prompt_template = DEFAULT_PROMPT_TEMPLATE
        print(f"âœ… Gemini å·²åˆå§‹åŒ–: {settings.google_model}")

    def extract_summary(self, analysis_text: str, page_num: int) -> str:
        """
        ä»åˆ†æç»“æœä¸­æå–å…³é”®æ‘˜è¦
        
        Args:
            analysis_text: å®Œæ•´çš„åˆ†ææ–‡æœ¬
            page_num: é¡µç 
            
        Returns:
            æ‘˜è¦æ–‡æœ¬
        """
        # æå–å‰200ä¸ªå­—ç¬¦ä½œä¸ºæ‘˜è¦
        lines = analysis_text.split('\n')
        summary_lines = []
        char_count = 0
        
        for line in lines:
            if char_count > 200:
                break
            if line.strip() and not line.startswith('#'):
                summary_lines.append(line.strip())
                char_count += len(line)
        
        summary = ' '.join(summary_lines)[:200]
        return f"[ç¬¬{page_num}é¡µæ‘˜è¦] {summary}"

    def build_context_string(self, previous_summaries: List[str]) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²"""
        if not previous_summaries:
            return ""
        
        context = "\n".join(previous_summaries)
        return f"\n\nğŸ“š å‰é¢é¡µé¢çš„å†…å®¹æ¦‚è¦:\n{context}\n"

    async def analyze_image(
        self,
        image: Image.Image,
        page_num: int,
        previous_summaries: Optional[List[str]] = None,
        temperature: float = 0.7,
        max_tokens: int = 50000,
    ) -> str:
        """åˆ†æå›¾åƒå¹¶ç”ŸæˆMarkdownæ ¼å¼è§£é‡Š"""
        
        # æ„å»ºæç¤ºè¯
        prompt = f"ã€ç¬¬ {page_num} é¡µã€‘\n\n{self.prompt_template}"
        
        # æ·»åŠ å‰é¢é¡µé¢çš„ä¸Šä¸‹æ–‡
        if previous_summaries:
            context_str = self.build_context_string(previous_summaries)
            prompt += context_str

        # ç”Ÿæˆé…ç½® - å¢åŠ  max_output_tokens
        config = genai.GenerationConfig(
            temperature=temperature,
            max_output_tokens=max_tokens,
        )

        # é‡è¯•æœºåˆ¶
        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = self.model.generate_content(
                    [prompt, image],
                    generation_config=config,
                    safety_settings=SAFETY_SETTINGS,
                )

                # æ£€æŸ¥æ˜¯å¦æœ‰å€™é€‰å“åº”
                if not response.candidates:
                    print(f"âš ï¸ ç¬¬ {page_num} é¡µï¼šæ— å€™é€‰å“åº”ï¼Œé‡è¯• {attempt + 1}/{max_retries}")
                    if attempt < max_retries - 1:
                        continue
                    return f"## ç¬¬ {page_num} é¡µ\n\nâš ï¸ æ— æ³•ç”Ÿæˆå†…å®¹ï¼Œè¯·ç¨åé‡è¯•ã€‚"

                candidate = response.candidates[0]

                # è®°å½•å®‰å…¨æ ‡è®°
                if candidate.finish_reason == 2:
                    print(f"âš ï¸ ç¬¬ {page_num} é¡µï¼šSAFETY æ ‡è®°")
                elif candidate.finish_reason == 3:
                    print(f"âš ï¸ ç¬¬ {page_num} é¡µï¼šRECITATION æ ‡è®°")

                # å°è¯•å¤šç§æ–¹å¼æå–æ–‡æœ¬
                extracted_text = None
                
                # æ–¹å¼1: ç›´æ¥ä» response.text è·å–
                try:
                    if hasattr(response, "text") and response.text:
                        extracted_text = response.text
                except ValueError as e:
                    # response.text å¯èƒ½å› ä¸ºå®‰å…¨åŸå› æŠ›å‡ºå¼‚å¸¸
                    print(f"âš ï¸ ç¬¬ {page_num} é¡µï¼šresponse.text å¼‚å¸¸: {str(e)[:100]}")

                # æ–¹å¼2: ä» candidate.content.parts æå–
                if not extracted_text and candidate.content and candidate.content.parts:
                    texts = []
                    for part in candidate.content.parts:
                        if hasattr(part, "text") and part.text:
                            texts.append(part.text)
                    if texts:
                        extracted_text = "\n".join(texts)

                # æ–¹å¼3: å°è¯•ä» candidate çš„å…¶ä»–å±æ€§æå–
                if not extracted_text:
                    try:
                        if hasattr(candidate, 'text') and candidate.text:
                            extracted_text = candidate.text
                    except:
                        pass

                if extracted_text and len(extracted_text.strip()) > 50:
                    return extracted_text
                elif extracted_text:
                    print(f"âš ï¸ ç¬¬ {page_num} é¡µï¼šå†…å®¹è¿‡çŸ­ ({len(extracted_text)} å­—ç¬¦)ï¼Œé‡è¯•")
                    if attempt < max_retries - 1:
                        continue
                    return extracted_text if extracted_text else f"## ç¬¬ {page_num} é¡µ\n\nâš ï¸ å†…å®¹ç”Ÿæˆä¸å®Œæ•´ã€‚"
                else:
                    print(f"âš ï¸ ç¬¬ {page_num} é¡µï¼šæ— æ³•æå–å†…å®¹ï¼Œé‡è¯• {attempt + 1}/{max_retries}")
                    if attempt < max_retries - 1:
                        continue
                    return f"## ç¬¬ {page_num} é¡µ\n\nâš ï¸ æ— æ³•æå–å†…å®¹ï¼Œå¯èƒ½æ˜¯å®‰å…¨è¿‡æ»¤å¯¼è‡´ã€‚"

            except Exception as e:
                print(f"âš ï¸ ç¬¬ {page_num} é¡µï¼šGemini API é”™è¯¯: {str(e)}")
                if attempt < max_retries - 1:
                    import asyncio
                    await asyncio.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
                    continue
                return f"## ç¬¬ {page_num} é¡µ\n\nâš ï¸ ç”Ÿæˆå¤±è´¥: {str(e)[:200]}"
        
        return f"## ç¬¬ {page_num} é¡µ\n\nâš ï¸ å¤šæ¬¡å°è¯•åä»æ— æ³•ç”Ÿæˆå†…å®¹ã€‚"


# å…¨å±€å•ä¾‹
llm_service = GeminiService()
